<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>概率论 on 狗蛋日</title><link>https://young-mann.top/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/</link><description>Recent content in 概率论 on 狗蛋日</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 23 Oct 2023 13:49:58 +0200</lastBuildDate><atom:link href="https://young-mann.top/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/index.xml" rel="self" type="application/rss+xml"/><item><title>重对数律</title><link>https://young-mann.top/posts/law-of-the-iterated-logarithm/</link><pubDate>Mon, 23 Oct 2023 13:49:58 +0200</pubDate><guid>https://young-mann.top/posts/law-of-the-iterated-logarithm/</guid><description>今天读 Mathematical Foundations for Finance 讲义里的布朗运动一章时，看到布朗运动的轨道满足一个以前没见过的 Law of the iterated logarithm，内容如下：
假设 $W=(W_t)_{t \geq 0}$ 是一个布朗运动，那么我们有：
$$ \begin{align} &amp;amp; \limsup\limits_{t \rightarrow \infty} = \frac{W_t}{\psi_{\text {glob }}(t)}=1, \mathbb{P}\text{-a.s.,} \\ &amp;amp; \liminf\limits_{t \rightarrow \infty} = \frac{W_t}{\psi_{\text {glob }}(t)}=-1, \mathbb{P}\text{-a.s.,} \end{align} $$
其中 $\psi_{\text {glob }}(t) := \sqrt{2t \log (\log t)}$。
粗糙点讲，这里 Law of the iterated logarithm 的含义是， 布朗运动的的样本路径几乎是被包含在 $\pm \psi_{\text {glob }}(t) $ 所组成的上下界内的。不过，由于这里是 $\lim \sup$，而非 $\sup$ ，所以样本路径有时候也会越过上下界。
t=1E6 且 n_path=500 时的布朗运动</description></item><item><title>小记概率论里的一些题</title><link>https://young-mann.top/posts/%E5%B0%8F%E8%AE%B0%E6%A6%82%E7%8E%87%E8%AE%BA%E9%87%8C%E7%9A%84%E4%B8%80%E4%BA%9B%E9%A2%98/</link><pubDate>Tue, 26 Sep 2023 20:09:07 +0200</pubDate><guid>https://young-mann.top/posts/%E5%B0%8F%E8%AE%B0%E6%A6%82%E7%8E%87%E8%AE%BA%E9%87%8C%E7%9A%84%E4%B8%80%E4%BA%9B%E9%A2%98/</guid><description>假设一对夫妻打算生孩子。他们采取的剩余策略是，除非连续生出3个女孩，否则一直生新的小孩。那么，现在的问题是，当这对夫妻停止生育时，他们已生下的小孩有多少个？ 为了回答这个问题，可以直接考虑不同小孩数量的概率。假设每次生育时，生出女孩的概率为$p$，生出男孩的概率为$q :=1-p$。那么，在这题里：
样本空间中的样本点 $\omega_i$ 是长度为 i 的已被生下来的小孩的性别序列。例如，$w_2 = BG$ 表示一共生了两个小孩，第一个是男孩，第二个是女孩； 我们设定一个随机变量 $\text{X}(\omega): \Omega \rightarrow \mathbb R$ 。这个随机变量需要输入一个样本点，即上文提到的性别序列，并输出所输入序列的长度值； 概率测度 $\text P(x) = \text P(\text{X}=x)$表示「这对夫妻停止生育时，他们已生下的小孩有 x 个」的概率。 不难求出以下递归形式， $$ \begin{align} \text P(1)&amp;amp;=0 \\ \text P(2)&amp;amp;=0 \\ \text P(3)&amp;amp;=p^3 \\ \text P(4)&amp;amp;=qp^3=q\text P(3) \\ \text P(5)&amp;amp;=q^2\text P(3)+qp\text P(3)=q\text P(4)+qp\text P(3) \\ \text P(6)&amp;amp;=q\text P(5)+qp\text P(4)+qp^2\text P(3) \\ \cdots \\ \text P(n)&amp;amp;=q\text P(n-1)+qp\text P(n-2)+qp^2\text P(n-3) \end{align} $$
取$p=0.5$，可得：
p=0.5
p=0.5; q=1-p; f=zeros(60,1); f(3)=p^3; for i=4:60 f(i)=q*f(i-1)+q*p*f(i-2)+q*p^2*f(i-3); end bar(f) Mathematical Statistics and Data Analysis (3rd Edition) (C1-11) Consider the binomial distribution with $n$ trials and probability $p$ of success on each trial.</description></item><item><title>金融数学中sigma代数的直观含义</title><link>https://young-mann.top/posts/sigma%E4%BB%A3%E6%95%B0%E7%9A%84%E7%9B%B4%E8%A7%82%E5%90%AB%E4%B9%89/</link><pubDate>Tue, 16 May 2023 14:31:37 +0800</pubDate><guid>https://young-mann.top/posts/sigma%E4%BB%A3%E6%95%B0%E7%9A%84%E7%9B%B4%E8%A7%82%E5%90%AB%E4%B9%89/</guid><description>sigma 代数表示的事件域代表每个阶段所知信息的多寡 简单来说，sigma 代数刻画的事件域 $\mathcal F$ 包含了一系列划分后的集合，后文称作「分类」，which 可以被我们用来对样本空间 $\Omega$ 中的样本路径 $\omega$ 进行归类。这些分类，实际上表示我们对于当前样本路径的了解程度：我们在某一阶段 $T$ 所知道的信息越多，这一阶段的事件域 $\mathcal F _T$ 所包含的元素就越多，表示我们 $\omega$ 所能采用的分类也就越多。
这些分类是怎样描述「所知道的信息」的？一种可行的思路是思路是，对于某个随机过程，我们会面临一条事前确定的样本路径 $\omega_i$ 。然而，尽管这条样本路径是已经被「固定」的，但我们并不知道 $\omega_i$ 是 $\Omega$ 中的哪一个 $\omega$ ——我们仅能知道，对于给定的 $\Omega$ 的某个子集，$\omega_i$ 是不是在这个子集里面。而前一句中 能够被判断是否包含 $\omega_i$ 的这些 $\Omega$ 的子集，就是我们在第一段中提到的，事件域 $\mathcal F$ 所包含的「分类」。如果对集合的划分越精细，「分类」就越多，表示我们知道的信息就更多。
一个例子 对于分类如何刻画信息，现在就来举个直观的例子。假设我现在要扔一枚质地均匀的硬币，扔个 2 次。将硬币的某一面记作正面，与其相反的一面记作反面。将「硬币投出了正面」记作 H （假设其可能性为 $p,p&amp;gt;0$ ），将「硬币投出了反面」记作 T （假设其可能性为 0&amp;quot;&amp;gt;$q, q=1-p&amp;gt;0$ ）。以一串序列 $\omega$ （其中 $\omega=\omega_1\omega_2$ ， 的可能取值为或$\omega_i的可能取值为H或T$ ）列出所有可能发生的结果，便可得样本空间 $\Omega = \lbrace \text{HH, HT, TH, TT}\rbrace.$
再定义一个随机变量 $S$ ，用于表示股票价格：
$$ \begin{align} S_0(\omega) &amp;amp;= 4, \forall \omega \in \Omega \\ S_1(\omega) &amp;amp;= \begin{cases} 8, &amp;amp; 如果 \omega_1=H \ 2, &amp;amp; 如果 \omega_1=T \ \end{cases} \\ S_2(\omega) &amp;amp;= \begin{cases} 16, &amp;amp; 如果 \omega_1=\omega_2=H \ 4, &amp;amp; 如果 \omega_1\neq \omega_2 \ 1, &amp;amp; 如果 \omega_1=\omega_2=T \end{cases} \end{align} $$</description></item><item><title>蒙特卡罗估计简介</title><link>https://young-mann.top/posts/monte-carlo/</link><pubDate>Thu, 20 Oct 2022 21:50:02 +0800</pubDate><guid>https://young-mann.top/posts/monte-carlo/</guid><description>本文是对《金融工程中的蒙特卡罗方法》一书的读书笔记。
蒙特卡洛原理 蒙特卡洛方法是什么？ 蒙特卡罗方法是一种用于模拟随机现象，以求得事件的概率的统计模拟方法。借助测度论的语言，我们可对概率论做一种公理化定义1，将随机试验中随机发生的事件与一个集合对应起来（这个集合包含了事件发生时的所有可能结果），将总体也与一个集合对应起来（这个集合包含了随机试验的所有可能结果），从而将概率定义为：
$$某事件的概率 := \frac{该事件对应集合的容量}{总体对应集合的容量}$$
确定了这个定义之后，我们便可以通过计算事件对应集合的容量与总体对应集合的容值，计算某个事件的概率——而实际上蒙特卡罗方法就是这么做的。比如，我们现在想要计算某个事件发生的概率。那么，我们可以做的是，在所有可能结果组成的总体中随机抽样，然后计算落入事件对应集合的样本点所占总体的比例，以此比例「估计」事件对应集合的容量。在这一过程中，大数定律保证了这个估计会随着抽样的增加而收敛于真实值2，中心极限定理则给出了在有限次抽样下估计误差的可能幅度。
为了更方便地计算集合的度量，我们可以引入积分这个工具。考虑一个简单的例子：假设我们现在需要估计一个给定函数$f$在单位区间上的积分值。为书写方便起见，我们可以将这个积分值记作 $\alpha$，则有： $$ \alpha = \int^1_0f(x) \mathop{}!\mathrm{d}x. $$ $\alpha$ 可以被看作期望值 $\mathbb{E}[f(U)]$，其中 $U \sim\text{Uniform}(0,1)$。假设我们可以在 $[0,1]$ 上独立均匀地抽样得到 $U_1,U_2,\cdots$，那么计算 $f$ 在这些样本点上的取值并求平均，便可得到欲求积分值的一个蒙特卡洛估计： $$ \hat \alpha n = \frac1n \sum^n{i=1}f(U_i). $$ 如果函数 $f$ 满足一些特定性质，我们就能得到一个误差较低的 $\alpha$ 估计值，并且可以显式地求出这个估计的误差值。
先来看看 $\alpha$ 的具体估计取值。如果函数 $f$ 在 $[0,1]$ 上可积，那么根据强大数定律，有： $$ 当\ n \to \infty \ 时,\ \hat \alpha_n \stackrel{a.s.} \longrightarrow \alpha. $$ 再来看看估计的误差值。如果函数 $f$ 平方可积，那么蒙特卡洛估计中的误差项 $\hat \alpha_n - \alpha$ 近似服从于 $\text{Normal}(0, {\sigma_f^2}/{ n})$，而且 $n$ 越大，这个误差项就越近似于上述的正态分布。需要补充的是，这个正态分布中的总体方差 $\sigma_f$ 定义如下： $$ \sigma_f^2 = \int^1_0 (f(x)-\alpha)^2 \mathop{}!</description></item><item><title>基于测度论的概率论基础</title><link>https://young-mann.top/posts/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/</link><pubDate>Thu, 14 Jul 2022 17:45:55 +0800</pubDate><guid>https://young-mann.top/posts/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/</guid><description>本文介绍了概率空间$ ( \Omega, \mathcal{F}, {P} )$ 中 $\Omega, \mathcal F, P$ ，尤其是 $\mathcal F$ 的含义——事件域 $\mathcal F$ 包含了一系列划分后的集合，which 可以被我们用来对样本空间 $\Omega$ 中的样本路径 $\omega$ 进行归类。这些分类，实际上表示我们对于当前样本路径的了解程度：我们在某一阶段 $T$ 所知道的信息越多，这一阶段的事件域 $\mathcal F _T$ 所包含的元素就越多，表示我们对于 $\omega$ 所能选取的划分也就越多。
1. 描述样本空间 $\Omega$ 及其子集 假设我们现在关心的是「连续投掷2次硬币」这一随机试验。将硬币的某一面记作正面，与其相反的一面记作反面。将「硬币投出了正面」记作 H （假设其可能性为 $p,p&amp;gt;0$），将「硬币投出了反面」记作 T （假设其可能性为 $q, q=1-p&amp;gt;0$）。这一随机试验中，以序列$w_1w_2$（其中$w_i的可能取值为H或T$）列出所有可能的结果。此时的样本空间 $\Omega$ 为： $$ \Omega = \lbrace \text{HH, HT, TH, TT}\rbrace. \ $$
样本空间 Ω 列出了随机试验所有可能发生的结果。在这些过程中，有一些结果可能是我们所关心的。我们可以根据所关心的 内容，对 Ω 中的元素进行划分1，并将划分中的元素称作事件。例如，我们可能想了解 第1次掷币的结果是否是正面 。此时，我们可对样本空间 $\Omega$ 进行如下的划分： $$ C_1=\lbrace第1次掷币的结果是正面\rbrace =\lbrace \text{HH, HT}\rbrace, \ C_2=\lbrace第1次掷币的结果是反面\rbrace =\lbrace\text{TH, TT}\rbrace .</description></item></channel></rss>