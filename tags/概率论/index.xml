<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>概率论 on 斐康明</title><link>https://young-mann.top/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/</link><description>Recent content in 概率论 on 斐康明</description><generator>Hugo</generator><language>en</language><lastBuildDate>Fri, 22 Mar 2024 14:59:52 +0100</lastBuildDate><atom:link href="https://young-mann.top/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/index.xml" rel="self" type="application/rss+xml"/><item><title>基于特征函数推导概率分布函数</title><link>https://young-mann.top/posts/proof-of-a-formula-about-cf-and-cdf/</link><pubDate>Fri, 22 Mar 2024 14:59:52 +0100</pubDate><guid>https://young-mann.top/posts/proof-of-a-formula-about-cf-and-cdf/</guid><description>&lt;h2 id="引言">引言&lt;/h2>
&lt;p>最近，笔者在某节课上学习了&lt;u>利用特征函数及FFT的期权定价方法&lt;/u>，which 需要用到特征函数反推概率分布函数，也就是下面这个等式：
$$
F(x) = \frac {1}{2} + \frac {1} {2\pi}\int ^{\infty} _{0} \frac {e^{itx} \phi(-t) - e^{-itx}\phi(t)} {it} \text{d}t,
$$
其中，$F(x)=F_Z(x)$是关于随机变量$Z$的概率分布函数，$\phi(t)=\phi_Z(t) :=\mathbb{E}[e^{itZ}] = \int^{+\infty} _{-\infty}e^{itz}\text{d}F(z)$ 是关于随机变量$Z$的特征函数，$i:=\sqrt{-1}$。&lt;/p>
&lt;p>然而，这节课的课件里没有这个表达式的推导过程。为了理解这个式子从何而来，笔者找到了&lt;a href="https://doi.org/10.1093/biomet/38.3-4.481">这篇文章&lt;/a>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>，将推导思路记了下来，写作本文。&lt;/p>
&lt;p>为简化符号，下文将继续省略概率分布函数、特征函数关于随机变量的下标。&lt;/p>
&lt;p>另外，笔者不确定下文中自己对「为什么可以交换积分次序」的证明是对是错。如果有大佬能指出其中的问题，那就在此提前感谢了。&lt;/p>
&lt;h2 id="推导过程">推导过程&lt;/h2>
&lt;p>第一步，任取$0&amp;lt;\varepsilon&amp;lt;\lambda$，硬凑积分如下：
$$
\begin{align}
\text{I}&amp;amp;= \frac {1} {\pi}\int ^\lambda _{\varepsilon} \frac {e^{itx} \phi(-t) - e^{-itx}\phi(t)} {it} \text{d}t
\nonumber
\\
&amp;amp;= \frac {1} {\pi} \int ^\lambda _{\varepsilon} \frac {e^{itx} \int^{+\infty} _{-\infty} e^{-itz} \text{d}F(z) - e^{-itx}\int^{+\infty} _{-\infty}e^{itz}\text{d}F(z)} {it} \text{d}t
\nonumber
\\
&amp;amp;= \frac{1}{\pi} \int ^\lambda _{\varepsilon} \int^{+\infty} _{-\infty} \frac {e^{i[t(x-z)]}- e^{i[-t(x-z)]}} {it}\text{d}F(z) \text{d}t
\\
&amp;amp;\xlongequal{\text{使用欧拉公式}} \frac{2}{\pi} \int ^{\lambda} _{\varepsilon} \int^{+\infty} _{-\infty} \frac {\sin(t(x-z))}{t} \text{d}F(z) \text{d}t
\\
&amp;amp;\xlongequal{\text{积分换序}}\int ^{+\infty} _{-\infty} \text{d}F(z) \frac{2}{\pi} \int ^{\lambda} _{\varepsilon} \frac {\sin(t(x-z))}{t} \text{d}t
\end{align}
$$&lt;/p></description></item><item><title>小记概率论里的一些题</title><link>https://young-mann.top/posts/%E5%B0%8F%E8%AE%B0%E6%A6%82%E7%8E%87%E8%AE%BA%E9%87%8C%E7%9A%84%E4%B8%80%E4%BA%9B%E9%A2%98/</link><pubDate>Tue, 26 Sep 2023 20:09:07 +0200</pubDate><guid>https://young-mann.top/posts/%E5%B0%8F%E8%AE%B0%E6%A6%82%E7%8E%87%E8%AE%BA%E9%87%8C%E7%9A%84%E4%B8%80%E4%BA%9B%E9%A2%98/</guid><description>&lt;details>&lt;summary>假设一对夫妻打算生孩子。他们采取的剩余策略是，除非连续生出3个女孩，否则一直生新的小孩。那么，现在的问题是，当这对夫妻停止生育时，他们已生下的小孩有多少个？&lt;/summary>
&lt;p>为了回答这个问题，可以直接考虑不同小孩数量的概率。假设每次生育时，生出女孩的概率为$p$，生出男孩的概率为$q :=1-p$。那么，在这题里：&lt;/p>
&lt;ul>
&lt;li>样本空间中的样本点 $\omega_i$ 是长度为 i 的已被生下来的小孩的性别序列。例如，$w_2 = BG$ 表示一共生了两个小孩，第一个是男孩，第二个是女孩；&lt;/li>
&lt;li>我们设定一个随机变量 $\text{X}(\omega): \Omega \rightarrow \mathbb R$ 。这个随机变量需要输入一个样本点，即上文提到的性别序列，并输出所输入序列的长度值；&lt;/li>
&lt;li>概率测度 $\text P(x) = \text P(\text{X}=x)$表示「这对夫妻停止生育时，他们已生下的小孩有 x 个」的概率。&lt;/li>
&lt;/ul>
&lt;p>不难求出以下递归形式，
$$
\begin{align}
\text P(1)&amp;amp;=0
\\
\text P(2)&amp;amp;=0
\\
\text P(3)&amp;amp;=p^3
\\
\text P(4)&amp;amp;=qp^3=q\text P(3)
\\
\text P(5)&amp;amp;=q^2\text P(3)+qp\text P(3)=q\text P(4)+qp\text P(3)
\\
\text P(6)&amp;amp;=q\text P(5)+qp\text P(4)+qp^2\text P(3)
\\
\cdots
\\
\text P(n)&amp;amp;=q\text P(n-1)+qp\text P(n-2)+qp^2\text P(n-3)
\end{align}
$$&lt;/p>
&lt;p>取$p=0.5$，可得：&lt;/p>
&lt;figure class="smaller">&lt;img src="https://s2.loli.net/2023/09/28/djxoFcCB4LHke1M.jpg"
 alt="p=0.5">&lt;figcaption>
 &lt;p>p=0.5&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-matlab" data-lang="matlab">&lt;span style="display:flex;">&lt;span>p=&lt;span style="color:#ae81ff">0.5&lt;/span>; 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>q=&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">-&lt;/span>p; 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f=zeros(&lt;span style="color:#ae81ff">60&lt;/span>,&lt;span style="color:#ae81ff">1&lt;/span>); 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f(&lt;span style="color:#ae81ff">3&lt;/span>)=p^&lt;span style="color:#ae81ff">3&lt;/span>; 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i=&lt;span style="color:#ae81ff">4&lt;/span>:&lt;span style="color:#ae81ff">60&lt;/span> 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f(i)=q&lt;span style="color:#f92672">*&lt;/span>f(i&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)&lt;span style="color:#f92672">+&lt;/span>q&lt;span style="color:#f92672">*&lt;/span>p&lt;span style="color:#f92672">*&lt;/span>f(i&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">+&lt;/span>q&lt;span style="color:#f92672">*&lt;/span>p^&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">*&lt;/span>f(i&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>); 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">end&lt;/span> 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bar(f)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/details>
&lt;h2 id="mathematical-statistics-and-data-analysis-3rd-edition">Mathematical Statistics and Data Analysis (3rd Edition)&lt;/h2>
&lt;details>&lt;summary>(C1-11) Consider the binomial distribution with $n$ trials and probability $p$ of success on each trial. For what value of $k$ is $P(X=k)$ maximized? This value is called the mode of the distribution. (Hint: Consider the ratio of successive terms.)&lt;/summary>
$$
\begin{aligned} \frac{P(X=k+1)}{P(X=k)} 
&amp; =\frac{C^{k+1}_n p^{k+1}(1-p)^{n-k-1}}{C^{k}_n p^k(1-p)^{n-k}}\\\
&amp;=\frac{p}{1-p} \cdot \frac{n-k}{k+1} .\end{aligned}
$$
&lt;p>随着k取值的增加，以上表达式中的比值会经历大于1（可能还会等于1）以及小于1的变化。我们希望找到能让上式小于1（即$\frac{p}{1-p} \cdot \frac{n-k}{k+1}&amp;lt;1$）的最小的k。易得：
$$
n p-k p&amp;lt;k-k p+1-p \Longleftrightarrow k&amp;gt;p \cdot(n+1)-1
$$&lt;/p></description></item><item><title>金融数学中sigma代数的直观含义</title><link>https://young-mann.top/posts/sigma%E4%BB%A3%E6%95%B0%E7%9A%84%E7%9B%B4%E8%A7%82%E5%90%AB%E4%B9%89/</link><pubDate>Tue, 16 May 2023 14:31:37 +0800</pubDate><guid>https://young-mann.top/posts/sigma%E4%BB%A3%E6%95%B0%E7%9A%84%E7%9B%B4%E8%A7%82%E5%90%AB%E4%B9%89/</guid><description>&lt;h2 id="sigma-代数表示的事件域代表每个阶段所知信息的多寡">sigma 代数表示的事件域代表每个阶段所知信息的多寡&lt;/h2>
&lt;p>简单来说，sigma 代数刻画的事件域 $\mathcal F$ 包含了一系列划分后的集合，后文称作「分类」，which 可以被我们用来对样本空间 $\Omega$ 中的样本路径 $\omega$ 进行归类。这些分类，实际上表示我们对于当前样本路径的了解程度：我们在某一阶段 $T$ 所知道的信息越多，这一阶段的事件域 $\mathcal F _T$ 所包含的元素就越多，表示我们 $\omega$ 所能采用的分类也就越多。&lt;/p>
&lt;p>这些分类是怎样描述「所知道的信息」的？一种可行的思路是思路是，对于某个随机过程，我们会面临一条事前确定的样本路径 $\omega_i$ 。然而，尽管这条样本路径是已经被「固定」的，但我们并不知道 $\omega_i$ 是 $\Omega$ 中的哪一个 $\omega$ ——我们仅能知道，&lt;u>&lt;strong>对于给定的 $\Omega$ 的某个子集，$\omega_i$ 是不是在这个子集里面&lt;/strong>&lt;/u>。而前一句中 能够被判断是否包含 $\omega_i$ 的这些 $\Omega$ 的子集，就是我们在第一段中提到的，事件域 $\mathcal F$ 所包含的「分类」。如果对集合的划分越精细，「分类」就越多，表示我们知道的信息就更多。&lt;/p>
&lt;h2 id="一个例子">一个例子&lt;/h2>
&lt;p>对于分类如何刻画信息，现在就来举个直观的例子。假设我现在要扔一枚质地均匀的硬币，扔个 2 次。将硬币的某一面记作正面，与其相反的一面记作反面。将「硬币投出了正面」记作 H （假设其可能性为 $p,p&amp;gt;0$ ），将「硬币投出了反面」记作 T （假设其可能性为 0&amp;quot;&amp;gt;$q, q=1-p&amp;gt;0$ ）。以一串序列 $\omega$ （其中 $\omega=\omega_1\omega_2$ ， 的可能取值为或$\omega_i的可能取值为H或T$ ）列出所有可能发生的结果，便可得样本空间 $\Omega = \lbrace \text{HH, HT, TH, TT}\rbrace.$&lt;/p>
&lt;p>再定义一个随机变量 $S$ ，用于表示股票价格：&lt;/p>
&lt;p>$$
\begin{align} S_0(\omega) &amp;amp;= 4, \forall \omega \in \Omega \\ S_1(\omega) &amp;amp;= \begin{cases} 8, &amp;amp; 如果 \omega_1=H \ 2, &amp;amp; 如果 \omega_1=T \ \end{cases} \\ S_2(\omega) &amp;amp;= \begin{cases} 16, &amp;amp; 如果 \omega_1=\omega_2=H \ 4, &amp;amp; 如果 \omega_1\neq \omega_2 \ 1, &amp;amp; 如果 \omega_1=\omega_2=T \end{cases} \end{align}
$$&lt;/p></description></item><item><title>蒙特卡罗估计简介</title><link>https://young-mann.top/posts/monte-carlo/</link><pubDate>Thu, 20 Oct 2022 21:50:02 +0800</pubDate><guid>https://young-mann.top/posts/monte-carlo/</guid><description>&lt;p>本文是对&lt;a href="https://book.douban.com/subject/25727712/">《金融工程中的蒙特卡罗方法》&lt;/a>一书的读书笔记。&lt;/p>
&lt;h2 id="蒙特卡洛原理">蒙特卡洛原理&lt;/h2>
&lt;h3 id="蒙特卡洛方法是什么">蒙特卡洛方法是什么？&lt;/h3>
&lt;p>蒙特卡罗方法是一种用于模拟随机现象，以求得事件的概率的统计模拟方法。借助测度论的语言，我们可对概率论做一种公理化定义&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>，将随机试验中随机发生的事件与一个集合对应起来（这个集合包含了事件发生时的所有可能结果），将总体也与一个集合对应起来（这个集合包含了随机试验的所有可能结果），从而将概率定义为：&lt;/p>
&lt;p>$$某事件的概率 := \frac{该事件对应集合的容量}{总体对应集合的容量}$$&lt;/p>
&lt;p>确定了这个定义之后，我们便可以通过计算事件对应集合的容量与总体对应集合的容值，计算某个事件的概率——而实际上蒙特卡罗方法就是这么做的。比如，我们现在想要计算某个事件发生的概率。那么，我们可以做的是，在所有可能结果组成的总体中随机抽样，然后计算落入事件对应集合的样本点所占总体的比例，以此比例「估计」事件对应集合的容量。在这一过程中，大数定律保证了这个估计会随着抽样的增加而收敛于真实值&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>，中心极限定理则给出了在有限次抽样下估计误差的可能幅度。&lt;/p>
&lt;p>为了更方便地计算集合的度量，我们可以引入积分这个工具。考虑一个简单的例子：假设我们现在需要估计一个给定函数$f$在单位区间上的积分值。为书写方便起见，我们可以将这个积分值记作 $\alpha$，则有：
$$
\alpha = \int^1_0f(x) \mathop{}!\mathrm{d}x.
$$
$\alpha$ 可以被看作期望值 $\mathbb{E}[f(U)]$，其中 $U \sim\text{Uniform}(0,1)$。假设我们可以在 $[0,1]$ 上独立均匀地抽样得到 $U_1,U_2,\cdots$，那么计算 $f$ 在这些样本点上的取值并求平均，便可得到欲求积分值的一个蒙特卡洛估计：
$$
\hat \alpha &lt;em>n = \frac1n \sum^n&lt;/em>{i=1}f(U_i).
$$
如果函数 $f$ 满足一些特定性质，我们就能得到一个误差较低的 $\alpha$ 估计值，并且可以显式地求出这个估计的误差值。&lt;/p>
&lt;p>先来看看 $\alpha$ 的具体估计取值。如果函数 $f$ 在 $[0,1]$ 上可积，那么根据强大数定律，有：
$$
当\ n \to \infty \ 时,\ \hat \alpha_n \stackrel{a.s.} \longrightarrow \alpha.
$$
再来看看估计的误差值。如果函数 $f$ 平方可积，那么蒙特卡洛估计中的误差项 $\hat \alpha_n - \alpha$ 近似服从于 $\text{Normal}(0, {\sigma_f^2}/{ n})$，而且 $n$ 越大，这个误差项就越近似于上述的正态分布。需要补充的是，这个正态分布中的总体方差 $\sigma_f$ 定义如下：
$$
\sigma_f^2 = \int^1_0 (f(x)-\alpha)^2 \mathop{}!\mathrm{d}x.
$$
要注意的是，上述 $\sigma_f$ 定义里用到了 $\alpha$ ，而这是一个总体的真实值，通常是未知的，从而导致 $\sigma_f$ 也是未知的。为了解决这个问题，我们可以转而使用样本标准差 $s_f$ 来估计误差值：
$$
s_f = \sqrt {\frac 1 {n-1} \sum^n_{i=1} (f(U_i) - \hat \alpha_i)^2}.
$$
至此，我们得到一个误差较低的 $\hat \alpha _n$ 估计值，以及本次估计的误差值 $s_f$。&lt;/p></description></item><item><title>基于测度论的概率论基础</title><link>https://young-mann.top/posts/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/</link><pubDate>Thu, 14 Jul 2022 17:45:55 +0800</pubDate><guid>https://young-mann.top/posts/%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E7%A1%80/</guid><description>&lt;p>本文介绍了概率空间$ ( \Omega, \mathcal{F}, {P} )$ 中 $\Omega, \mathcal F, P$ ，尤其是 $\mathcal F$ 的含义——事件域 $\mathcal F$ 包含了一系列划分后的集合，which 可以被我们用来对样本空间 $\Omega$ 中的样本路径 $\omega$ 进行归类。这些分类，实际上表示我们对于当前样本路径的了解程度：我们在某一阶段 $T$ 所知道的信息越多，这一阶段的事件域 $\mathcal F _T$ 所包含的元素就越多，表示我们对于 $\omega$ 所能选取的划分也就越多。&lt;/p>
&lt;h2 id="1-描述样本空间-omega-及其子集">1. 描述样本空间 $\Omega$ 及其子集&lt;/h2>
&lt;p>假设我们现在关心的是「连续投掷2次硬币」这一随机试验。将硬币的某一面记作正面，与其相反的一面记作反面。将「硬币投出了正面」记作 H （假设其可能性为 $p,p&amp;gt;0$），将「硬币投出了反面」记作 T （假设其可能性为 $q, q=1-p&amp;gt;0$）。这一随机试验中，以序列$w_1w_2$（其中$w_i的可能取值为H或T$）列出所有可能的结果。此时的样本空间 $\Omega$ 为：
$$
\Omega = \lbrace \text{HH, HT, TH, TT}\rbrace. \
$$&lt;/p>
&lt;p>样本空间 Ω 列出了随机试验所有可能发生的结果。在这些过程中，有一些结果可能是我们所关心的。我们可以根据所关心的 内容，对 Ω 中的元素进行&lt;strong>划分&lt;/strong>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>，并将划分中的元素称作&lt;strong>事件&lt;/strong>。例如，我们可能想了解 &lt;u>第1次掷币的结果是否是正面&lt;/u> 。此时，我们可对样本空间 $\Omega$ 进行如下的划分：
$$
C_1=\lbrace第1次掷币的结果是正面\rbrace =\lbrace \text{HH, HT}\rbrace,
\
C_2=\lbrace第1次掷币的结果是反面\rbrace =\lbrace\text{TH, TT}\rbrace .
\
$$
根据注释1&lt;sup id="fnref1:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>中对划分的定义，不难验证， $ C_1\cap C_2=\varnothing$ 且 $C_1 \cup C_2 = \Omega$，所以 $\lbrace \text{HH, HT}\rbrace, \lbrace \text{TH, TT}\rbrace$ 是 $\Omega$ 的一个划分，而 &lt;u>第1次掷币的结果是否是正面&lt;/u> 便是我们关心的事件。&lt;/p></description></item></channel></rss>